# Optimize hdfs config for prod

The default config of hdfs can't be used in the production environment. The below config need to be adjusted to make your
cluster work correctly.

The official hadoop doc can be found [here](https://hadoop.apache.org/docs). Choose the version which you use, and check
the config parameters. For example, we use 3.3.6, the config params for [hdfs-site.xml](https://hadoop.apache.org/docs/r3.3.6/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml)

## 0. Check hardware (network, diskIO)

### 0.1 Check Disk IO performance

Here we use a tool called **fio** to check the disk read/write speed

```shell
sudo apt install fio

# check sequential read speed
sudo fio -filename=/tmp/test.log -direct=1 -iodepth 1 -thread -rw=read -ioengine=psync -bs=16k -size=2G -numjobs=10 \
-runtime=60 -group_reporting -name=test_r

# check sequential write speed
sudo fio -filename=/tmp/test.log -direct=1 -iodepth 1 -thread -rw=write -ioengine=psync -bs=16k -size=2G -numjobs=10 \
-runtime=60 -group_reporting -name=test_w

# check random write
sudo fio -filename=/tmp/test.log -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=16k -size=2G -numjobs=10 \
-runtime=60 -group_reporting -name=test_randw

# check mix random read/write

sudo fio -filename=/tmp/test.log -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=2G -numjobs=10 \
-runtime=60 -group_reporting -name=test_rand_r_w
```

## 1. hdfs-site.xml optimization

io.file.buffer.size?

### 1.1. Optimize name node

1. **dfs.namenode.handler.count**: The number of Namenode RPC server threads that listen to requests from clients. If **dfs.namenode.servicerpc-address** 
               is not configured then Namenode RPC server threads listen to requests from all nodes. The default value is `10`. The recommend 
                value is calculated with the below python script `python -c 'import math ; print int(math.log(N) * 20)`.
2. **dfs.namenode.avoid.read.stale.datanode**: Indicate whether to avoid reading from "stale" datanodes whose heartbeat messages have not been received by the namenode for more than a specified time interval. 
                  Stale datanodes will be moved to the end of the node list returned for reading. See dfs.namenode.avoid.write.stale.datanode for a similar setting for writes.
3. **dfs.namenode.avoid.write.stale.datanode** same for write

### 1.2 Optimize data node

1. **dfs.datanode.max.transfer.threads**: Specifies the maximum number of threads to use for transferring data in and out of the DN. 
                The default value is `4096`, the recommended value is `8192`
2. **dfs.datanode.handler.count**:  The number of server threads for the datanode. The default value is 10

### 1.3 

When a datanode finished writing a block, it will report to the name node immediately. This will generate many useless connection
if you have many writes.

We can ask the datanode to wait a little bit, so all the writes during this wait time will be reported in one signle connexion.
This can reduce the network workload.

**dfs.blockreport.incremental.intervalMsec** :	If set to a positive integer, the value in ms to wait between sending incremental block reports from the Datanode to the Namenode.
    The default value is `0`(no wait time). We recommend 1000 ms (1 second)


## 2. JVM heap memory optimization

### 2.1 Examine the namenode and datanode heap memory utilisation

```shell
# show processes in the jvm
jps

# with option v, it shows all arguments in the java_opts
jps -lv

# output example
13077 jdk.jcmd/sun.tools.jps.Jps -Dapplication.home=/usr/lib/jvm/java-11-openjdk-amd64 -Xms8m -Djdk.module.main=jdk.jcmd
2391 org.apache.hadoop.hdfs.server.namenode.NameNode -Dproc_namenode -Djava.net.preferIPv4Stack=true -Dhdfs.audit.logger=INFO,NullAppender -XX:+UseG1GC -XX:InitialHeapSize=2g -XX:MaxHeapSize=2g -XX:MaxGCPauseMillis=500 -XX:+DisableExplicitGC -XX:+UseStringDeduplication -XX:+ParallelRefProcEnabled -XX:MaxMetaspaceSize=256m -XX:MaxTenuringThreshold=1 -Xlog:gc=ERROR:file=/tmp/gc.log:time,uptime,level,tags:filecount=5,filesize=100m -Dyarn.log.dir=/opt/hadoop/logs -Dyarn.log.file=hadoop-hadoop-namenode-spark-m01.log -Dyarn.home.dir=/opt/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/hadoop/lib/native -Xmx2048m -Xms1024m -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=hadoop-hadoop-namenode-spark-m01.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender
2586 org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode -Dproc_secondarynamenode -Djava.net.preferIPv4Stack=true -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dyarn.log.dir=/opt/hadoop/logs -Dyarn.log.file=hadoop-hadoop-secondarynamenode-spark-m01.log -Dyarn.home.dir=/opt/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/hadoop/lib/native -Xmx2048m -Xms1024m -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=hadoop-hadoop-secondarynamenode-spark-m01.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml

```

Now we have the process id. We can have more details on the process by using:
- jcmd: It shows the heap and metaspace related info of a running Java application. 
- jstat: Doing the same with more information

#### Use jcmd to check the namenode process

```shell
jcmd 2391 GC.heap_info

# output example
2391:
 garbage-first heap   total 1048576K, used 125839K [0x0000000080000000, 0x0000000100000000)
  region size 1024K, 69 young (70656K), 0 survivors (0K)
 Metaspace       used 44222K, capacity 44939K, committed 45568K, reserved 294912K
  class space    used 4410K, capacity 4671K, committed 4864K, reserved 253952K

# output example
2391:
VM Arguments:
jvm_args: -Dproc_namenode -Djava.net.preferIPv4Stack=true -Dhdfs.audit.logger=INFO,NullAppender -XX:+UseG1GC -XX:InitialHeapSize=2g -XX:MaxHeapSize=2g -XX:MaxGCPauseMillis=500 -XX:+DisableExplicitGC -XX:+UseStringDeduplication -XX:+ParallelRefProcEnabled -XX:MaxMetaspaceSize=256m -XX:MaxTenuringThreshold=1 -Xlog:gc=ERROR:file=/tmp/gc.log:time,uptime,level,tags:filecount=5,filesize=100m -Dyarn.log.dir=/opt/hadoop/logs -Dyarn.log.file=hadoop-hadoop-namenode-spark-m01.log -Dyarn.home.dir=/opt/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/hadoop/lib/native -Xmx2048m -Xms1024m -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=hadoop-hadoop-namenode-spark-m01.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender 
java_command: org.apache.hadoop.hdfs.server.namenode.NameNode
java_class_path (initial): /opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-dns-4.1.89.Final.jar
Launcher Type: SUN_STANDARD

```

1. The `garbage-first`: means it used G1GC as garbage collector
2. `heap` : shows total heap 1048576K(1024MB), used 125839(122.9MB)
3. G1 regions are 1 MB, there are 69 regions marked as young, and 0 as survivors space
4. The current capacity of the metaspace is around 43.89 MB (44939 K). From that 43.89 MB, around 43.2 MB (12983 K) is used. 
Also, we can have up to 288MB of metaspace (294912 K). Moreover, 45568 KB guaranteed to be available for use by 
the Java virtual machine, also known as committed memory
5. The last line shows how much of the metaspace is used to store class information

#### Use jcmd to show jvm arguments

```shell
jcmd 2391 VM.command_line
```

#### Use jstat 

```shell
jstat -gc 2391

# output example
S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT    CGC    CGCT     GCT   
 0.0    0.0    0.0    0.0   660480.0 82944.0   388096.0   55183.0   45568.0 44222.4 4864.0 4410.9     17    0.183   2      0.153   6      0.032    0.368

```
The output means:
- **S0C** : The capacity for the first survivor space
- **S1C** :  The capacity for the second survivor space
- **S0U** :  The used space of the first survivor
- **S1U** :  The used space of the second survivor
- **EC** :  Eden space capacity
- **EU**:   Used space from Eden
- **OC**:  Old generation capacity
- **OU**:  Used space from Old generation
- **MC**:  Metaspace capacity
- **MU**:  Used space from Metaspace
- **CCSC**:  Compressed class space capacity
- **CCSU**:  Used space for compressed classes
- **YGC**:  The number of minor GCs
- **YGCT**:  The time spent for minor GCs
- **FGC**:  The number of full GCs
- **FGCT**:  The time spent for full GCs
- **CGC**:  The number of concurrent GCs
- **CGCT**:  Time spent on concurrent GCs
- **GCT**:  The time spent for all GCs


There are other memory-related options for jstat such as:

 - The `-gccapacity` to report different capacities for different memory regions
 - The `-gcutil` only shows the utilization percentage of each region
 - The `-gccause` is the same as -gcutil but adds the cause of the last GC and possibly current GC events

You can modify the jvm heap config in **hadoop-env.sh** config file.

### 2.2 Namenode

The minimum heap memory for namenode is 1GB(1000000 block), for another 1 millions blocks, we need to add another 1GB
heap memory
```shell
export HDFS_NAMENODE_OPTS="-Dhadoop.security.logger=INFO,RFAS -Xmx18g"
```

### 2.3 Datanode
The minimum heap memory for datanode is 4GB, for another 1 millions blocks, add 1GB

```shell
#
export HDFS_DATANODE_OPTS="-Dhadoop.security.logger=ERROR,RFAS -Xmx18g"
```

## 3. Config to control replication copy speed

To increase the speed of the replicat copy, we need to modify three params in **hdfs-site.xml**

### 3.1. For Namenode: Change the replication iteration number

**dfs.namenode.replication.work.multiplier.per.iteration**: it defines the block number which a data node can duplicate
during one heartbeat. The default value is 2. By increasing this number, the copy speed increase too. But the datanode
process will consume more resource too.

For example, if a cluster has 500 nodes, and the iteration=10. It means for one heartbeat, the namenode can send a list
of 10*500=5000 block. If we decommission one node which contains 800000 block, it will take 800000/(500*10)=160 heartbeat
if one heartbeat takes every 3 sec. The total time will be 160*3 = 480 seconds.

> If the datanodes is fixed in a cluster, increase the iteration number increase the speed.

For our cluster, we set the value to 5.

### 3.2. For Datanode: 

Block copy priorities:
1. L1(highest): when a block has 0 duplicates in the cluster, the block has the possibility to be lost(no failure). So the block copy has the highest priority.
2. L2: when a block has minimum duplicates(less than 1/3 of the expected duplication number), 
3. L3: has better block duplicat number than L2
4. L4: block has the minimum duplication number.
5. L5: the block has error, but it has enough duplicats works normally

We need to modify the below two params  
1. **dfs.namenode.replication.max-streams**: It defines the max thread number which will be used to copy the block inside the datanode.
   The block copy process has 5 different type of priorities, the L1 copy process are not limited by this configuration.
   The default value is 2. we recommend 10 

2. **dfs.namenode.replication.max-streams-hard-limit**: It defines the max thread number which will be used to copy the block which
   has the priority L1. The default value is 4, we recommend 20.




## 5. Linux kernel config optimization (not sure of this)

**net.core.somaxconn** is a parameter in Linux kernel, it defines the max queue length number of the backlog. The backlog
is a queue which stores the request(not treated or establishing connexion) of sockets. In high highloaded server, if this
number is not high enough, the queue for waiting request will not have the capacity to stores all untreated request.
https://serverfault.com/questions/518862/will-increasing-net-core-somaxconn-make-a-difference

> I don't think our cluster have this problem for now.
